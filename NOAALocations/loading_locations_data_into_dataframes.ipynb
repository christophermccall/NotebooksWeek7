{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a single JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function called read_json. Given a string representing a file path to a json file, this function should open said file and convert its contens into a json object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement me\n",
    "def read_json(file_path):\n",
    "    with open(file_path) as f:\n",
    "        data = json.loads(f.read())\n",
    "        j_obj = json.dumps(data['results'], indent=4)\n",
    "    return j_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the read_json function defined above to read the contents of one of the locations_4.json file acquired in the Data Acquisition Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('./', 'data', 'locations', 'locations_4.json')\n",
    "json_contents = read_json(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the value of the json_contents variable defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert JSON Into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the json_contents variable, create a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/3381114193.py:3: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_json(json_contents)\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame here.\n",
    "\n",
    "df = pd.read_json(json_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the contents of the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>name</th>\n",
       "      <th>datacoverage</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1905-05-08</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Phillips County, MT</td>\n",
       "      <td>1</td>\n",
       "      <td>FIPS:30071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1911-03-01</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Pondera County, MT</td>\n",
       "      <td>1</td>\n",
       "      <td>FIPS:30073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1893-02-01</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Powder River County, MT</td>\n",
       "      <td>1</td>\n",
       "      <td>FIPS:30075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1893-01-01</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Powell County, MT</td>\n",
       "      <td>1</td>\n",
       "      <td>FIPS:30077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1904-11-01</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Prairie County, MT</td>\n",
       "      <td>1</td>\n",
       "      <td>FIPS:30079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1915-04-01</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Gonzales County, TX</td>\n",
       "      <td>1</td>\n",
       "      <td>FIPS:48177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1907-01-27</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Gray County, TX</td>\n",
       "      <td>1</td>\n",
       "      <td>FIPS:48179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1897-05-01</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Grayson County, TX</td>\n",
       "      <td>1</td>\n",
       "      <td>FIPS:48181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1902-01-01</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Gregg County, TX</td>\n",
       "      <td>1</td>\n",
       "      <td>FIPS:48183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1914-06-01</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Grimes County, TX</td>\n",
       "      <td>1</td>\n",
       "      <td>FIPS:48185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mindate     maxdate                     name  datacoverage          id\n",
       "0    1905-05-08  2024-04-11      Phillips County, MT             1  FIPS:30071\n",
       "1    1911-03-01  2024-04-11       Pondera County, MT             1  FIPS:30073\n",
       "2    1893-02-01  2024-04-11  Powder River County, MT             1  FIPS:30075\n",
       "3    1893-01-01  2024-04-11        Powell County, MT             1  FIPS:30077\n",
       "4    1904-11-01  2024-04-11       Prairie County, MT             1  FIPS:30079\n",
       "..          ...         ...                      ...           ...         ...\n",
       "995  1915-04-01  2024-04-11      Gonzales County, TX             1  FIPS:48177\n",
       "996  1907-01-27  2024-04-11          Gray County, TX             1  FIPS:48179\n",
       "997  1897-05-01  2024-04-11       Grayson County, TX             1  FIPS:48181\n",
       "998  1902-01-01  2024-04-11         Gregg County, TX             1  FIPS:48183\n",
       "999  1914-06-01  2024-04-11        Grimes County, TX             1  FIPS:48185\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display contents of the DataFrame here.\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many records are in the DataFrame? How many columns does each record have? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the contents of the DataFrame to only show records where the name column contains the string \"Durham\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>name</th>\n",
       "      <th>datacoverage</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1891-01-01</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Durham County, NC</td>\n",
       "      <td>1</td>\n",
       "      <td>FIPS:37063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mindate     maxdate               name  datacoverage          id\n",
       "295  1891-01-01  2024-04-11  Durham County, NC             1  FIPS:37063"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "df[df.name.str.contains('Durham')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Multiple JSON Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function called read_all_json_files. Given a string representing a path to a directory, this function should read all of the json files and return a Pandas DataFrame containing all of the objects. In addition to the data from the files, this DataFrame should also contain an additional column called \"source\". The source column should be populated with the name of the file from which this record originated from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('./', 'data', 'locations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement me\n",
    "def read_all_json_files(JSON_ROOT):\n",
    "    df_list = []\n",
    "    for file in os.listdir(JSON_ROOT):\n",
    "        if '.json' in str(file):\n",
    "            new_file_path = os.path.join('./', 'data', 'locations',file)\n",
    "            new_json_contents = read_json(new_file_path)\n",
    "            new_df = pd.read_json(new_json_contents)\n",
    "            new_df['source'] = file\n",
    "            df_list.append(new_df)\n",
    "            print(str(new_file_path))\n",
    "    cat_df = pd.concat(df_list)\n",
    "    return cat_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the read_all_json_files function above to read the contents of all locations file acquired in the the Data Acquisition Lab.  \n",
    "Hint: It is easier if you put all of those files in a dedicated subdirectory ex: (./data/locations/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/locations/locations_10.json\n",
      "./data/locations/locations_26.json\n",
      "./data/locations/locations_30.json\n",
      "./data/locations/locations_3.json\n",
      "./data/locations/locations_2.json\n",
      "./data/locations/locations_31.json\n",
      "./data/locations/locations_27.json\n",
      "./data/locations/locations_11.json\n",
      "./data/locations/locations_20.json\n",
      "./data/locations/locations_36.json\n",
      "./data/locations/locations_5.json\n",
      "./data/locations/locations_9.json\n",
      "./data/locations/locations_16.json\n",
      "./data/locations/locations_17.json\n",
      "./data/locations/locations_8.json\n",
      "./data/locations/locations_4.json\n",
      "./data/locations/locations_37.json\n",
      "./data/locations/locations_21.json\n",
      "./data/locations/locations_18.json\n",
      "./data/locations/locations_7.json\n",
      "./data/locations/locations_34.json\n",
      "./data/locations/locations_22.json\n",
      "./data/locations/locations_14.json\n",
      "./data/locations/locations_38.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/locations/locations_15.json\n",
      "./data/locations/locations_23.json\n",
      "./data/locations/locations_35.json\n",
      "./data/locations/locations_6.json\n",
      "./data/locations/locations_19.json\n",
      "./data/locations/locations_12.json\n",
      "./data/locations/locations_28.json\n",
      "./data/locations/locations_1.json\n",
      "./data/locations/locations_32.json\n",
      "./data/locations/locations_24.json\n",
      "./data/locations/locations_25.json\n",
      "./data/locations/locations_33.json\n",
      "./data/locations/locations_0.json\n",
      "./data/locations/locations_29.json\n",
      "./data/locations/locations_13.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n",
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/1738099983.py:8: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  new_df = pd.read_json(new_json_contents)\n"
     ]
    }
   ],
   "source": [
    "df2 = read_all_json_files('data/locations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the shape of the DataFrame? Does this match the number of columns and records you expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the shape of the DataFrame here\n",
    "df2.shape[0]\n",
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first few records of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>name</th>\n",
       "      <th>datacoverage</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1948-05-01</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Highgate Center, VT 05459</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ZIP:05459</td>\n",
       "      <td>locations_10.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-05-08</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Hinesburg, VT 05461</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ZIP:05461</td>\n",
       "      <td>locations_10.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1955-11-01</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Huntington, VT 05462</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ZIP:05462</td>\n",
       "      <td>locations_10.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-03-06</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Isle la Motte, VT 05463</td>\n",
       "      <td>0.95</td>\n",
       "      <td>ZIP:05463</td>\n",
       "      <td>locations_10.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-05-08</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Jeffersonville, VT 05464</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ZIP:05464</td>\n",
       "      <td>locations_10.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mindate     maxdate                       name  datacoverage         id  \\\n",
       "0  1948-05-01  2024-04-11  Highgate Center, VT 05459          1.00  ZIP:05459   \n",
       "1  1995-05-08  2024-04-11        Hinesburg, VT 05461          1.00  ZIP:05461   \n",
       "2  1955-11-01  2024-04-11       Huntington, VT 05462          1.00  ZIP:05462   \n",
       "3  1997-03-06  2024-04-11    Isle la Motte, VT 05463          0.95  ZIP:05463   \n",
       "4  1995-05-08  2024-04-11   Jeffersonville, VT 05464          1.00  ZIP:05464   \n",
       "\n",
       "              source  \n",
       "0  locations_10.json  \n",
       "1  locations_10.json  \n",
       "2  locations_10.json  \n",
       "3  locations_10.json  \n",
       "4  locations_10.json  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first few records\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the last few records of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>name</th>\n",
       "      <th>datacoverage</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38857</th>\n",
       "      <td>1994-06-15</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Mont Clare, PA 19453</td>\n",
       "      <td>0.95</td>\n",
       "      <td>ZIP:19453</td>\n",
       "      <td>locations_13.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38858</th>\n",
       "      <td>1972-01-01</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>North Wales, PA 19454</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ZIP:19454</td>\n",
       "      <td>locations_13.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38859</th>\n",
       "      <td>1894-01-01</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Phoenixville, PA 19460</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ZIP:19460</td>\n",
       "      <td>locations_13.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38860</th>\n",
       "      <td>1994-06-15</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Plymouth Meeting, PA 19462</td>\n",
       "      <td>0.95</td>\n",
       "      <td>ZIP:19462</td>\n",
       "      <td>locations_13.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38861</th>\n",
       "      <td>1894-01-01</td>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>Pottstown, PA 19464</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ZIP:19464</td>\n",
       "      <td>locations_13.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mindate     maxdate                        name  datacoverage  \\\n",
       "38857  1994-06-15  2024-04-11        Mont Clare, PA 19453          0.95   \n",
       "38858  1972-01-01  2024-04-11       North Wales, PA 19454          1.00   \n",
       "38859  1894-01-01  2024-04-11      Phoenixville, PA 19460          1.00   \n",
       "38860  1994-06-15  2024-04-11  Plymouth Meeting, PA 19462          0.95   \n",
       "38861  1894-01-01  2024-04-11         Pottstown, PA 19464          1.00   \n",
       "\n",
       "              id             source  \n",
       "38857  ZIP:19453  locations_13.json  \n",
       "38858  ZIP:19454  locations_13.json  \n",
       "38859  ZIP:19460  locations_13.json  \n",
       "38860  ZIP:19462  locations_13.json  \n",
       "38861  ZIP:19464  locations_13.json  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the last few records\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Records Are Unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide two different ways to determine there are no duplicate records.  \n",
    "Hint: The id field should be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y_/88_bvhts341bf74krgd3hgch0000gp/T/ipykernel_79322/2657285642.py:2: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  df2[pd.unique('id')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZIP:05459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZIP:05461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZIP:05462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZIP:05463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZIP:05464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38857</th>\n",
       "      <td>ZIP:19453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38858</th>\n",
       "      <td>ZIP:19454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38859</th>\n",
       "      <td>ZIP:19460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38860</th>\n",
       "      <td>ZIP:19462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38861</th>\n",
       "      <td>ZIP:19464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38862 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id\n",
       "0      ZIP:05459\n",
       "1      ZIP:05461\n",
       "2      ZIP:05462\n",
       "3      ZIP:05463\n",
       "4      ZIP:05464\n",
       "...          ...\n",
       "38857  ZIP:19453\n",
       "38858  ZIP:19454\n",
       "38859  ZIP:19460\n",
       "38860  ZIP:19462\n",
       "38861  ZIP:19464\n",
       "\n",
       "[38862 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one way to determine there are not duplicate records\n",
    "df2[pd.unique('id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>name</th>\n",
       "      <th>datacoverage</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [mindate, maxdate, name, datacoverage, id, source]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way to determine there are no duplicate records\n",
    "df2[df2.duplicated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peking In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the record with id \"CITY:TU000041\". Which file did it come from? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>name</th>\n",
       "      <th>datacoverage</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30863</th>\n",
       "      <td>1974-08-01</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>Mersin, TU</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CITY:TU000041</td>\n",
       "      <td>locations_1.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mindate     maxdate        name  datacoverage             id  \\\n",
       "30863  1974-08-01  2024-04-09  Mersin, TU           1.0  CITY:TU000041   \n",
       "\n",
       "                 source  \n",
       "30863  locations_1.json  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "df2[df2['id'] == 'CITY:TU000041'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the record with id \"CLIM:0405\". Which file did it come from? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4001    locations_2.json\n",
       "Name: source, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "df2[df2['id'] == 'CLIM:0405']['source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique values are there for the source column in the DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "df2['source'].unique().shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many records did the locations_38.json file contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "df2[df2['source'] == 'locations_38.json'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with this DataFrame in a subsequent part of the lab. Instead of repeating all of this work again, let's export the DataFrame to a pickled file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export DataFrame to a pickled file called locations_data_frame.pickle. Save it to the data directory.\n",
    "df2.to_pickle('../pickled jsons df2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
